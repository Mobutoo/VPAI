# {{ ansible_managed }}
# docker-compose.yml â€” Phase B: Applications, Monitoring, System
# Infrastructure services (PG, Redis, Qdrant, Caddy) are managed by docker-compose-infra.yml
# Networks created by docker-compose-infra.yml (external: true)

services:
  # === APPLICATION LAYER ===
  n8n:
    image: {{ n8n_image }}
    container_name: {{ project_name }}_n8n
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
    env_file:
      - /opt/{{ project_name }}/configs/n8n/n8n.env
    volumes:
      - /opt/{{ project_name }}/data/n8n:/home/node/.n8n
    networks:
      - backend
      - egress
    deploy:
      resources:
        limits:
          memory: {{ n8n_memory_limit }}
          cpus: "{{ n8n_cpu_limit }}"
        reservations:
          memory: {{ n8n_memory_reservation }}
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost:5678/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s

  litellm:
    image: {{ litellm_image }}
    container_name: {{ project_name }}_litellm
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
    env_file:
      - /opt/{{ project_name }}/configs/litellm/litellm.env
    volumes:
      - /opt/{{ project_name }}/configs/litellm/litellm_config.yaml:/app/config.yaml:ro
    command: --config /app/config.yaml --port 4000
    networks:
      - backend
      - egress
    deploy:
      resources:
        limits:
          memory: {{ litellm_memory_limit }}
          cpus: "{{ litellm_cpu_limit }}"
        reservations:
          memory: {{ litellm_memory_reservation }}
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost:4000/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  openclaw:
    image: {{ openclaw_image }}
    container_name: {{ project_name }}_openclaw
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
    env_file:
      - /opt/{{ project_name }}/configs/openclaw/openclaw.env
    networks:
      - backend
      - egress
    deploy:
      resources:
        limits:
          memory: {{ openclaw_memory_limit }}
          cpus: "{{ openclaw_cpu_limit }}"
        reservations:
          memory: {{ openclaw_memory_reservation }}
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost:8080/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # === MONITORING LAYER ===
  victoriametrics:
    image: {{ victoriametrics_image }}
    container_name: {{ project_name }}_victoriametrics
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
      - DAC_OVERRIDE
      - FOWNER
    command:
      - "-storageDataPath=/storage"
      - "-retentionPeriod=30d"
      - "-httpListenAddr=:8428"
    volumes:
      - /opt/{{ project_name }}/data/victoriametrics:/storage
    networks:
      - monitoring
    deploy:
      resources:
        limits:
          memory: {{ victoriametrics_memory_limit }}
          cpus: "{{ victoriametrics_cpu_limit }}"
        reservations:
          memory: {{ victoriametrics_memory_reservation }}
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:8428/-/healthy || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  loki:
    image: {{ loki_image }}
    container_name: {{ project_name }}_loki
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
      - DAC_OVERRIDE
      - FOWNER
    volumes:
      - /opt/{{ project_name }}/data/loki:/loki
      - /opt/{{ project_name }}/configs/loki/loki-config.yaml:/etc/loki/local-config.yaml:ro
    command: -config.file=/etc/loki/local-config.yaml
    networks:
      - monitoring
    deploy:
      resources:
        limits:
          memory: {{ loki_memory_limit }}
          cpus: "{{ loki_cpu_limit }}"
        reservations:
          memory: {{ loki_memory_reservation }}
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3100/ready || exit 1"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 60s

  alloy:
    image: {{ alloy_image }}
    container_name: {{ project_name }}_alloy
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
      - SYS_PTRACE
      - DAC_READ_SEARCH
    volumes:
      - /opt/{{ project_name }}/configs/alloy/config.alloy:/etc/alloy/config.alloy:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /var/log:/var/log:ro
    command: run --server.http.listen-addr=0.0.0.0:12345 /etc/alloy/config.alloy
    networks:
      - backend
      - monitoring
    deploy:
      resources:
        limits:
          memory: {{ alloy_memory_limit }}
          cpus: "{{ alloy_cpu_limit }}"
        reservations:
          memory: {{ alloy_memory_reservation }}
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:12345/-/ready || exit 1"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 30s

  grafana:
    image: {{ grafana_image }}
    container_name: {{ project_name }}_grafana
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
    environment:
      GF_SECURITY_ADMIN_USER: "{{ grafana_admin_user }}"
      GF_SECURITY_ADMIN_PASSWORD: "{{ grafana_admin_password }}"
      GF_USERS_ALLOW_SIGN_UP: "false"
      GF_SERVER_ROOT_URL: "https://{{ caddy_admin_domain }}/grafana/"
      GF_SERVER_SERVE_FROM_SUB_PATH: "true"
    volumes:
      - /opt/{{ project_name }}/data/grafana:/var/lib/grafana
      - /opt/{{ project_name }}/configs/grafana/provisioning:/etc/grafana/provisioning:ro
      - /opt/{{ project_name }}/configs/grafana/dashboards:/var/lib/grafana/dashboards:ro
    networks:
      - frontend
      - monitoring
    deploy:
      resources:
        limits:
          memory: {{ grafana_memory_limit }}
          cpus: "{{ grafana_cpu_limit }}"
        reservations:
          memory: {{ grafana_memory_reservation }}
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 30s

  # === SYSTEM ===
  diun:
    image: {{ diun_image }}
    container_name: {{ project_name }}_diun
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - DAC_OVERRIDE
      - FOWNER
    environment:
      TZ: "{{ timezone }}"
      CONFIG: "/diun.yml"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /opt/{{ project_name }}/data/diun:/data
      - /opt/{{ project_name }}/configs/diun/diun.yml:/diun.yml:ro
    deploy:
      resources:
        limits:
          memory: {{ diun_memory_limit }}
          cpus: "{{ diun_cpu_limit }}"
        reservations:
          memory: {{ diun_memory_reservation }}

networks:
  frontend:
    name: {{ project_name }}_frontend
    external: true
  backend:
    name: {{ project_name }}_backend
    external: true
  monitoring:
    name: {{ project_name }}_monitoring
    external: true
  egress:
    name: {{ project_name }}_egress
    external: true
