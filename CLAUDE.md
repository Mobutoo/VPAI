# CLAUDE.md â€” Instructions pour Claude Code

## IdentitÃ© du Projet

Ce repository est un projet **Ansible** qui dÃ©ploie une stack AI/automatisation auto-hÃ©bergÃ©e sur un VPS unique avec Docker Compose. Le projet est conÃ§u comme un **template portable** : toutes les valeurs sont des variables Jinja2, aucun nom de projet ou serveur n'est hardcodÃ©.

## AccÃ¨s GitHub

- **Repository** : `Mobutoo/VPAI` (privÃ©)
- **Remote** : `git@github-seko:Mobutoo/vpai.git`
- **Host SSH** : `github-seko` (configurÃ© dans `~/.ssh/config`, utilise la clÃ© `~/.ssh/id_ed25519_seko`)
- **Branche principale** : `main`
- **Compte GitHub** : Mobutoo

> **Important** : Toujours utiliser `github-seko` comme host dans les commandes git, jamais `github.com` directement. C'est un alias SSH pour le bon couple clÃ©/compte.

## Documents de RÃ©fÃ©rence

**Lire OBLIGATOIREMENT avant de coder :**

1. `PRD.md` â€” Vision produit, wizard de configuration (variables), objectifs, contraintes, architecture fonctionnelle. **âš ï¸ Fichier sensible, dans `.gitignore`, jamais pushÃ© sur GitHub.**
2. `PRD.md.example` â€” Version template du PRD avec les champs Ã  remplir (pushÃ©e sur GitHub)
3. `TECHNICAL-SPEC.md` â€” Architecture technique dÃ©taillÃ©e, configs, rÃ©seaux Docker, limites ressources, CI/CD
4. `docs/GOLDEN-PROMPT.md` â€” Plan de dÃ©veloppement en 6 phases avec checklists de review et **REX des erreurs rencontrÃ©es**

## Stack Technique

- **Orchestration** : Ansible 2.16+ (collections community.general, community.docker, ansible.posix)
- **Conteneurisation** : Docker CE + Docker Compose V2 (plugin)
- **Reverse Proxy** : Caddy (TLS auto, rate limiting, ACL VPN)
- **DonnÃ©es** : PostgreSQL 18.1, Redis 8.0.10, Qdrant v1.16.3
- **Applications** : n8n 2.7.3, OpenClaw v2026.2.9, LiteLLM v1.81.3-stable
- **ObservabilitÃ©** : Grafana 12.3.2, VictoriaMetrics v1.135.0, Loki 3.6.5, Alloy v1.13.0
- **SystÃ¨me** : DIUN 4.31.0, CrowdSec, Fail2ban, UFW
- **Backup** : Zerobyte v0.16 (sur serveur VPN distant, orchestrÃ© via cron local)
- **Monitoring externe** : Uptime Kuma (sur serveur VPN distant)
- **VPN** : Headscale/Tailscale (mesh VPN, dÃ©jÃ  dÃ©ployÃ© sur serveur VPN)
- **CI/CD** : GitHub Actions (lint â†’ molecule â†’ deploy preprod â†’ smoke tests)

## Conventions et RÃ¨gles Strictes

### Ansible

- **FQCN obligatoire** pour tous les modules : `ansible.builtin.apt`, `community.general.ufw`, etc. Jamais `apt` ou `ufw` seul
- **`changed_when` / `failed_when`** explicites sur toutes les tÃ¢ches `command` et `shell`
- **`set -euo pipefail`** en premiÃ¨re ligne de tout script shell (inline ou template)
- **Pas de `command`/`shell`** si un module Ansible existe pour la tÃ¢che
- **Idempotence** : chaque rÃ´le doit pouvoir s'exÃ©cuter 2 fois consÃ©cutives avec 0 changed Ã  la 2Ã¨me
- **Variables** : toujours dans `defaults/main.yml` (overridable) ou `vars/main.yml` (fixes)
- **Handlers** : utiliser `notify` + handler pour tout restart de service
- **Tags** : chaque rÃ´le a un tag correspondant Ã  son nom (ex: `tags: [postgresql]`)
- **Pas de `become: yes` global** : le mettre au niveau de la tÃ¢che quand nÃ©cessaire

### Docker

- **Jamais `:latest`** ni `:stable` â€” toutes les images sont pinnÃ©es dans `inventory/group_vars/all/versions.yml`
- **4 rÃ©seaux nommÃ©s** : `frontend`, `backend` (internal), `monitoring` (internal), `egress` â€” voir TECHNICAL-SPEC section 2
- **Limites mÃ©moire/CPU** sur chaque container â€” voir TECHNICAL-SPEC section 2.5
- **Healthchecks Docker** sur chaque service â€” voir TECHNICAL-SPEC section 8
- **`restart: unless-stopped`** sur tous les services
- **Log rotation** via daemon.json (max-size 10m, max-file 3)
- **Pas de `network_mode: host`** sauf DIUN (qui a besoin du Docker socket)

### Templates Jinja2

- **Toute valeur configurable** utilise une variable du wizard (`{{ project_name }}`, `{{ domain_name }}`, etc.)
- **Pas de valeur hardcodÃ©e** : `grep -r 'seko\|Seko' .` ne doit renvoyer que des variables/commentaires, jamais des valeurs en dur
- **Extension `.j2`** pour tous les templates

### SÃ©curitÃ©

- **SSH** : port custom, bind sur IP Headscale uniquement, clÃ© publique only
- **Secrets** : tous dans `inventory/group_vars/all/secrets.yml` chiffrÃ© avec Ansible Vault
- **Jamais de secret en clair** dans les fichiers YAML, templates, ou scripts
- **Admin UIs** (n8n, Grafana, OpenClaw, Qdrant) : accessibles uniquement via VPN (Caddy ACL)
- **Seuls ports publics** : 80 (redirect HTTPS) et 443 (TLS)

### Documentation

- Chaque rÃ´le a un `README.md` avec : description, variables (tableau), dÃ©pendances, exemple
- Chaque rÃ´le a un rÃ©pertoire `molecule/default/` avec converge.yml et verify.yml

## Structure du Repository

```
.
â”œâ”€â”€ .github/workflows/          # CI/CD pipelines
â”œâ”€â”€ inventory/
â”‚   â”œâ”€â”€ hosts.yml               # Inventaire (prod + preprod)
â”‚   â””â”€â”€ group_vars/all/         # Variables globales
â”‚       â”œâ”€â”€ main.yml            # Config wizard (depuis PRD.md section 2.1)
â”‚       â”œâ”€â”€ versions.yml        # Images Docker pinnÃ©es (depuis PRD.md section 2.3)
â”‚       â”œâ”€â”€ docker.yml          # Config Docker (daemon, rÃ©seaux, limites)
â”‚       â””â”€â”€ secrets.yml         # Ansible Vault (chiffrÃ©)
â”œâ”€â”€ roles/                      # 16 rÃ´les Ansible
â”‚   â””â”€â”€ <role>/
â”‚       â”œâ”€â”€ tasks/main.yml
â”‚       â”œâ”€â”€ handlers/main.yml
â”‚       â”œâ”€â”€ defaults/main.yml
â”‚       â”œâ”€â”€ vars/main.yml       # (si nÃ©cessaire)
â”‚       â”œâ”€â”€ templates/
â”‚       â”œâ”€â”€ files/
â”‚       â”œâ”€â”€ meta/main.yml
â”‚       â”œâ”€â”€ molecule/default/
â”‚       â”‚   â”œâ”€â”€ molecule.yml
â”‚       â”‚   â”œâ”€â”€ converge.yml
â”‚       â”‚   â””â”€â”€ verify.yml
â”‚       â””â”€â”€ README.md
â”œâ”€â”€ playbooks/                  # Playbooks utilitaires
â”œâ”€â”€ scripts/                    # Scripts helper
â”œâ”€â”€ templates/                  # Templates partagÃ©s (docker-compose.yml.j2)
â”œâ”€â”€ docs/                       # Documentation opÃ©rationnelle
â”œâ”€â”€ PRD.md                      # Product Requirements Document (LOCAL ONLY, dans .gitignore)
â”œâ”€â”€ PRD.md.example              # Template PRD avec champs Ã  remplir (pushÃ© sur GitHub)
â”œâ”€â”€ TECHNICAL-SPEC.md           # SpÃ©cification technique
â”œâ”€â”€ docs/GOLDEN-PROMPT.md       # Plan de dÃ©veloppement + REX erreurs
â”œâ”€â”€ ansible.cfg
â”œâ”€â”€ requirements.yml
â”œâ”€â”€ Makefile
â”œâ”€â”€ .yamllint.yml
â”œâ”€â”€ .ansible-lint
â””â”€â”€ README.md
```

## Commandes Utiles

```bash
# Linting
make lint                                    # yamllint + ansible-lint
ansible-lint playbooks/site.yml              # Lint complet

# Tests Molecule
make test                                    # Tous les rÃ´les
molecule test -s default -- roles/common     # Un rÃ´le spÃ©cifique

# DÃ©ploiement
make deploy-preprod                          # PrÃ©-production Hetzner
make deploy-prod                             # Production (avec confirmation)

# Vault
ansible-vault edit inventory/group_vars/all/secrets.yml
ansible-vault encrypt_string 'my_secret' --name 'variable_name'

# VÃ©rification
ansible-playbook playbooks/site.yml --check --diff   # Dry run
ansible-inventory --list                              # VÃ©rifier l'inventaire
```

## Ordre de DÃ©veloppement

Suivre les 6 phases du `docs/GOLDEN-PROMPT.md` dans l'ordre. Chaque phase a un checkpoint de review.

**Phase 1** â†’ common, hardening, docker, headscale-node
**Phase 2** â†’ caddy, postgresql, redis, qdrant
**Phase 3** â†’ n8n, openclaw, litellm
**Phase 4** â†’ monitoring (VM + Loki + Alloy + Grafana), diun
**Phase 5** â†’ backup-config, uptime-config, smoke-tests
**Phase 6** â†’ CI/CD workflows, documentation, polish

## Points d'Attention SpÃ©cifiques

### PostgreSQL 18.1
C'est un **major upgrade** depuis 17.x. Si migration d'un systÃ¨me existant, `pg_upgrade` est requis. Pour un nouveau dÃ©ploiement, pas de problÃ¨me.

### Redis 8.0
**Major upgrade** depuis 7.x. Nouvelles features : I/O threading (+30% perf), JSON memory (-92%). VÃ©rifier la compatibilitÃ© des clients.

### RÃ©seau `egress`
LiteLLM, n8n et OpenClaw ont besoin d'**accÃ¨s internet sortant** (appels API OpenAI/Anthropic, webhooks). Le rÃ©seau `backend` est `internal: true` donc pas d'internet. Ces 3 services doivent aussi Ãªtre sur le rÃ©seau `egress` (non-internal).

### Zerobyte sur Seko-VPN
Zerobyte n'est **pas** dÃ©ployÃ© par ce projet. Il tourne dÃ©jÃ  sur le serveur VPN. Ce projet :
1. PrÃ©pare les scripts pre-backup (pg_dump, redis save, etc.) sur le VPS prod
2. Documente la configuration Zerobyte dans le RUNBOOK

### Uptime Kuma sur Seko-VPN
MÃªme logique : dÃ©jÃ  dÃ©ployÃ©. Ce projet documente les monitors Ã  crÃ©er manuellement.

---

## PiÃ¨ges Connus et RÃ¨gles de QualitÃ© (REX)

Ces rÃ¨gles ont Ã©tÃ© dÃ©couvertes lors du dÃ©veloppement initial. **Les respecter Ã©limine 100% des erreurs de lint rencontrÃ©es.**

### Encodage et Fins de Ligne

- **TOUS les fichiers YAML/Jinja2 doivent Ãªtre en UTF-8 avec fins de ligne LF (Unix)**
- **Jamais de CRLF (Windows)** : yamllint Ã©choue avec `wrong new line character: expected \n`
- **Jamais de Windows-1252** : yamllint crash avec `UnicodeDecodeError: 'utf-8' codec can't decode byte 0x97`
- **Attention au tiret long** : `â€”` (em dash, U+2014) est le piÃ¨ge principal. En Windows-1252 c'est le byte `0x97` qui casse le parsing UTF-8
- **VÃ©rification** : `file roles/*/tasks/main.yml` doit afficher `UTF-8 Unicode text` pour tous les fichiers, jamais `ISO-8859` ou `CRLF`
- **Fix si besoin** : `find roles/ -name '*.yml' -exec sed -i 's/\r$//' {} \;` pour les CRLF

### ansible-lint â€” PiÃ¨ges SpÃ©cifiques

- **`name:` du play et variables** : Les templates Jinja2 dans le champ `name:` d'un **play** ne peuvent PAS utiliser de variables d'inventaire
  - âŒ `- name: "Deploy {{ project_display_name }}"` (inventaire pas encore chargÃ©)
  - âœ… `- name: "Deploy Full Stack"` (nom statique pour le play)
  - âœ… Dans les tasks : `msg: "Project: {{ project_display_name }}"` (variables disponibles)
  - **Pourquoi** : Le `name:` du play est parsÃ© avant le chargement des variables d'inventaire
  - **Erreur rencontrÃ©e** : `Error processing keyword 'name': 'project_display_name' is undefined`
- **`schema[meta]`** : Le `role_name` dans `meta/main.yml` doit correspondre au pattern `^[a-z][a-z0-9_]+$`
  - âŒ `role_name: headscale-node` (tirets interdits)
  - âœ… `role_name: headscale_node` (underscores OK, le dossier peut garder le tiret)
- **`syntax-check`** : ansible-lint exÃ©cute un syntax-check sans inventaire. Les variables comme `project_display_name` sont indÃ©finies â†’ configurer `extra_vars` dans `.ansible-lint`
- **`offline: true`** : Obligatoire dans `.ansible-lint` si pas de Galaxy configurÃ©, sinon erreur `Required config 'url' for 'galaxy' galaxy_server plugin`
- **`playbooks_dir`** : PropriÃ©tÃ© supprimÃ©e dans ansible-lint 26.x, ne plus l'utiliser

### ansible.cfg â€” Callback Plugins

- **`community.general.yaml` supprimÃ©** : Le callback plugin `community.general.yaml` a Ã©tÃ© retirÃ© dans community.general 12.0.0+
  - âŒ `stdout_callback = yaml` (ancien plugin community.general)
  - âœ… `stdout_callback = ansible.builtin.default` + `callback_result_format = yaml` (ansible-core 2.13+)
- **Erreur rencontrÃ©e** : `[ERROR]: The 'community.general.yaml' callback plugin has been removed`
- **Solution** : Utiliser le plugin intÃ©grÃ© avec l'option `result_format=yaml`

### yamllint â€” Configuration Requise

- **`octal-values`** : ansible-lint exige `forbid-implicit-octal: true` et `forbid-explicit-octal: true` dans `.yamllint.yml`
- **`secrets.yml`** : Le fichier Vault chiffrÃ© doit Ãªtre dans le `ignore:` de `.yamllint.yml` ET exclu du `find` dans le Makefile

### Makefile â€” Commande Lint

- **Ne PAS utiliser** `yamllint .` directement â€” cela scanne les fichiers Vault chiffrÃ©s et crash
- **Utiliser** `find` avec exclusions et `xargs` :
  ```makefile
  find . \( -name '*.yml' -o -name '*.yaml' \) \
    ! -path './.git/*' ! -path './.venv/*' \
    ! -path '*/molecule/*' ! -path '*/collections/*' \
    ! -name 'secrets.yml' -print0 | xargs -0 yamllint -c .yamllint.yml
  ```
- **Grouper les `-o`** dans `find` avec `\( ... \)`, sinon le comportement est incorrect

### Grafana Alloy

- **Format HCL** (HashiCorp Configuration Language), pas YAML Prometheus
- **Monter `/proc` et `/sys`** en read-only pour les mÃ©triques node_exporter :
  ```yaml
  volumes:
    - /proc:/host/proc:ro
    - /sys:/host/sys:ro
  ```
- **Healthcheck** : `wget -qO- http://localhost:12345/-/ready`

### DIUN

- **PrÃ©fÃ©rer un fichier de config** (`diun.yml.j2`) plutÃ´t que des variables d'environnement â€” plus lisible et plus flexible pour la notification conditionnelle
- **Docker socket** montÃ© en read-only : `/var/run/docker.sock:/var/run/docker.sock:ro`

### Port SSH et Premier DÃ©ploiement

- **ProblÃ¨me** : Au premier dÃ©ploiement, le VPS Ã©coute sur le port **22** (dÃ©faut SSH), mais `prod_ssh_port` dans `main.yml` contient le port custom (ex: 804)
- **Erreur rencontrÃ©e** : `ssh: connect to host <IP> port 804: Connection refused`
- **Solution** : L'inventaire utilise `ansible_port: "{{ ansible_port_override | default(22) }}"` pour se connecter sur le port 22 au dÃ©part
- **AprÃ¨s hardening** : Le rÃ´le `hardening` configure le port custom (via `prod_ssh_port_target`), et les dÃ©ploiements suivants utilisent `-e ansible_port_override=804`
- **Important** : Le `prod_ssh_port` dans le wizard est le port **cible** (aprÃ¨s hardening), pas le port actuel du VPS

### âš ï¸ CRITIQUE - Lockout SSH par Hardening

- **ProblÃ¨me** : Le rÃ´le `hardening` restreint SSH au VPN AVANT que le VPN ne soit validÃ© â†’ lockout immÃ©diat
- **Erreur rencontrÃ©e** : `Connection timed out` aprÃ¨s le rÃ´le hardening, impossible de se reconnecter
- **Cause racine** :
  - Hardening Ã©tait en Phase 1 (trop tÃ´t)
  - `hardening_ssh_force_open: false` par dÃ©faut (dangereux)
  - SSH configurÃ© sur `ListenAddress {{ vpn_headscale_ip }}` avant que le VPN ne fonctionne
- **Solution appliquÃ©e** :
  - Hardening dÃ©placÃ© en **Phase 6** (DERNIER rÃ´le, aprÃ¨s toutes les validations)
  - `hardening_ssh_force_open: true` par dÃ©faut (SSH reste sur 0.0.0.0)
  - L'admin doit explicitement mettre `false` APRÃˆS avoir confirmÃ© que le VPN fonctionne
- **PrÃ©vention** : **TOUJOURS garder une fenÃªtre SSH ouverte** pendant le premier dÃ©ploiement
- **RÃ©cupÃ©ration si lockout** :
  ```bash
  # Depuis la console VPS ou une session SSH encore ouverte
  sudo sed -i 's/^ListenAddress.*/ListenAddress 0.0.0.0/' /etc/ssh/sshd_config
  sudo systemctl restart sshd
  sudo ufw allow 22/tcp
  ```

### PostgreSQL 18+ - Breaking Changes Volume & Capabilities

- **ProblÃ¨me** : PostgreSQL 18.1 crash loop avec `chmod: changing permissions: Operation not permitted`
- **Cause racine 1 - Volume Mount** :
  - âŒ Ancien format (< 18) : `/var/lib/postgresql/data`
  - âœ… Nouveau format (18+) : `/var/lib/postgresql` (avec subdirs par version)
  - RÃ©fÃ©rence : https://github.com/docker-library/postgres/pull/1259
- **Cause racine 2 - Capabilities insuffisantes** :
  - PostgreSQL 18+ nÃ©cessite `DAC_OVERRIDE` et `FOWNER` en plus de `CHOWN`, `SETGID`, `SETUID`
  - Sans ces capabilities, impossible de `chmod`/`chown` dans `/var/lib/postgresql/18/docker`
- **Solution appliquÃ©e** :
  ```yaml
  # docker-compose-infra.yml
  volumes:
    - /opt/{{ project_name }}/data/postgresql:/var/lib/postgresql  # CorrigÃ©
  cap_add:
    - CHOWN
    - SETGID
    - SETUID
    - DAC_OVERRIDE  # Bypass file permission checks
    - FOWNER        # Bypass ownership checks
  ```
- **SÃ©curitÃ©** : Toujours `cap_drop: ALL` d'abord, puis ajout minimal. UID 999 non-root.
- **Migration depuis PG 17** : NÃ©cessite `pg_upgrade` si donnÃ©es existantes

### RÃ´le docker-stack et Architecture PhasÃ©e

- **ProblÃ¨me** : Aucun conteneur crÃ©Ã© car aucun rÃ´le ne faisait `docker compose up`
- **Solution** : CrÃ©ation du rÃ´le `docker-stack` en **Phase 4.5**
- **Architecture dÃ©ploiement en 2 phases** :
  - **Phase A (Infra)** : PostgreSQL, Redis, Qdrant, Caddy + RÃ©seaux isolÃ©s
  - **Phase B (Apps)** : n8n, LiteLLM, OpenClaw, Monitoring (`failed_when: false`)
- **RÃ©seaux Docker isolÃ©s** (conforme TECHNICAL-SPEC) :
  - `frontend` (172.20.1.0/24) : Public (Caddy, Grafana)
  - `backend` (172.20.2.0/24) : Internal, NO internet (PostgreSQL, Redis, Qdrant)
  - `egress` (172.20.4.0/24) : Apps avec internet (n8n, LiteLLM, OpenClaw)
  - `monitoring` (172.20.3.0/24) : Internal, NO internet (VictoriaMetrics, Loki)
- **Cleanup automatique** : Suppression anciens stacks/rÃ©seaux avant dÃ©ploiement (idempotence)

### Provisioning n8n - Ordre d'ExÃ©cution

- **ProblÃ¨me** : RÃ´le `n8n` essayait de provisionner l'owner AVANT crÃ©ation du conteneur
- **Erreur** : `docker exec javisi_n8n` â†’ `No such container`
- **Solution** : SÃ©paration en 2 rÃ´les :
  - **n8n (Phase 3)** : PrÃ©pare configs UNIQUEMENT
  - **n8n-provision (Phase 4.6)** : Provisionne owner APRÃˆS docker-stack
- **Principe** : Config avant conteneurs, provisioning aprÃ¨s conteneurs

### Images Docker - VÃ©rification Obligatoire

- **ProblÃ¨me** : `redis:8.0.10-bookworm` et `openclaw:v2026.2.14` inexistants
- **Solution** :
  - `redis:8.0-bookworm` (tag patch n'existe pas)
  - `openclaw:latest` (temporaire, TODO: pinner version stable)
- **PrÃ©vention** : VÃ©rifier TOUTES les images AVANT dÃ©ploiement
  ```bash
  for image in $(list_all); do
    docker manifest inspect "$image" || echo "ERREUR: $image"
  done
  ```

### RÃ©seaux Docker - Conflit de Labels Compose

- **ProblÃ¨me** : `network javisi_backend has incorrect label com.docker.compose.network`
- **Cause** : RÃ©seaux crÃ©Ã©s par ancien compose avec labels diffÃ©rents
- **Solution** : Cleanup automatique dans docker-stack/tasks/main.yml
  ```yaml
  - name: Remove project Docker networks if they exist
    ansible.builtin.command:
      cmd: "docker network rm {{ project_name }}_{{ item }}"
    loop: [frontend, backend, egress, monitoring]
    failed_when: false
  ```

### ConnectivitÃ© VPN - Check Non-Bloquant

- **ProblÃ¨me** : `ping 87.106.30.160` Ã©chouait car VPS utilise son propre routage (pas de route VPN)
- **Solution** : VÃ©rification VPN avec `failed_when: false` (non-bloquante)
- **Principe** : VPN mesh != routage automatique. Le VPS garde son routage normal.

### Environnement de DÃ©veloppement (WSL)

- **venv Python** : Utiliser `.venv/` pour installer ansible-lint et yamllint (`python3 -m venv .venv`)
- **Activer le venv** avant `make lint` : `source .venv/bin/activate && make lint`
- **`.venv/`** est dans `.gitignore`

---

## ğŸ“‹ REX Complet Premier DÃ©ploiement

Voir `docs/REX-FIRST-DEPLOY-2026-02-15.md` pour :
- Analyse dÃ©taillÃ©e des 8 erreurs critiques
- Commits de correction avec rationale
- Architecture finale dÃ©ployÃ©e
- Checklist code review pour Opus 4.6
- Recommandations futurs dÃ©ploiements
