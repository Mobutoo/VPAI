{
  "name": "AI Model Scoring",
  "nodes": [
    {
      "parameters": {
        "rule": {
          "interval": [
            {
              "field": "cronExpression",
              "expression": "0 */6 * * *"
            }
          ]
        }
      },
      "id": "d4e5f6a7-4001-4000-8004-000000000001",
      "name": "Cron 6h",
      "type": "n8n-nodes-base.scheduleTrigger",
      "typeVersion": 1.2,
      "position": [260, 100]
    },
    {
      "parameters": {
        "method": "GET",
        "url": "http://litellm:4000/spend/logs",
        "authentication": "none",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "=Bearer {{ $env.LITELLM_API_KEY }}"
            }
          ]
        },
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "start_date",
              "value": "={{ new Date(Date.now() - 6*60*60*1000).toISOString().split('T')[0] }}"
            },
            {
              "name": "end_date",
              "value": "={{ new Date().toISOString().split('T')[0] }}"
            }
          ]
        },
        "options": {
          "response": {
            "response": {
              "fullResponse": true
            }
          },
          "timeout": 30000
        }
      },
      "id": "d4e5f6a7-4001-4000-8004-000000000002",
      "name": "Fetch Spend Logs",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [480, 100]
    },
    {
      "parameters": {
        "jsCode": "// Aggregate spend logs by model — PostgreSQL as source of truth + JSON cache export\nconst { Client } = require('pg');\nconst fs = require('fs');\n\nconst client = new Client({\n  host: 'postgresql',\n  port: 5432,\n  database: 'n8n',\n  user: 'n8n',\n  password: $env.DB_POSTGRESDB_PASSWORD\n});\n\ntry {\n  await client.connect();\n\n  const response = $input.first().json;\n  const logs = response.body || response || [];\n  const now = new Date().toISOString();\n  let logsProcessed = 0;\n\n  if (Array.isArray(logs)) {\n    for (const log of logs) {\n      const model = log.model || 'unknown';\n      const isSuccess = (log.status === 'success' || !log.status) ? 1 : 0;\n      const isFail = isSuccess ? 0 : 1;\n      const tokens = log.total_tokens || 0;\n      const cost = log.spend || 0;\n      const latency = log.completion_time_ms || 0;\n\n      await client.query(`\n        INSERT INTO model_scores (model, total_calls, successful_calls, failed_calls,\n          total_tokens, total_cost, total_latency_ms, source, first_seen, last_updated)\n        VALUES ($1, 1, $2, $3, $4, $5, $6, 'litellm', NOW(), NOW())\n        ON CONFLICT (model) DO UPDATE SET\n          total_calls = model_scores.total_calls + 1,\n          successful_calls = model_scores.successful_calls + $2,\n          failed_calls = model_scores.failed_calls + $3,\n          total_tokens = model_scores.total_tokens + $4,\n          total_cost = model_scores.total_cost + $5,\n          total_latency_ms = model_scores.total_latency_ms + $6,\n          last_updated = NOW()\n      `, [model, isSuccess, isFail, tokens, cost, latency]);\n      logsProcessed++;\n    }\n  }\n\n  // Recalculate scores for all models\n  const allModels = await client.query('SELECT * FROM model_scores');\n  const rows = allModels.rows;\n  const maxCost = Math.max(...rows.map(r => r.total_calls > 0 ? r.total_cost / r.total_calls : 0), 0.001);\n  const maxLatency = Math.max(...rows.map(r => r.total_calls > 0 ? r.total_latency_ms / r.total_calls : 0), 1);\n\n  for (const r of rows) {\n    const likeRatio = (r.likes + r.dislikes) > 0 ? r.likes / (r.likes + r.dislikes) : 0.5;\n    const successRate = r.total_calls > 0 ? r.successful_calls / r.total_calls : 1;\n    const avgCost = r.total_calls > 0 ? r.total_cost / r.total_calls : 0;\n    const costEff = 1 - (avgCost / maxCost);\n    const avgLatency = r.total_calls > 0 ? r.total_latency_ms / r.total_calls : 0;\n    const speedScore = 1 - (avgLatency / maxLatency);\n    const score = Math.round((likeRatio * 40) + (successRate * 30) + (costEff * 20) + (speedScore * 10));\n    const avgCostRound = Math.round(avgCost * 10000) / 10000;\n    const avgLatRound = Math.round(avgLatency);\n\n    await client.query(\n      'UPDATE model_scores SET score = $1, avg_cost_per_call = $2, avg_latency_ms = $3 WHERE model = $4',\n      [score, avgCostRound, avgLatRound, r.model]\n    );\n  }\n\n  // Export JSON cache for fast reads by OpenClaw skills\n  const updated = await client.query('SELECT * FROM model_scores ORDER BY score DESC');\n  const scoresObj = {};\n  for (const r of updated.rows) {\n    scoresObj[r.model] = {\n      total_calls: r.total_calls, successful_calls: r.successful_calls,\n      failed_calls: r.failed_calls, total_tokens: Number(r.total_tokens),\n      total_cost: r.total_cost, total_latency_ms: r.total_latency_ms,\n      likes: r.likes, dislikes: r.dislikes, score: r.score,\n      avg_cost_per_call: r.avg_cost_per_call, avg_latency_ms: r.avg_latency_ms,\n      source: r.source, first_seen: r.first_seen, last_updated: r.last_updated\n    };\n  }\n  const SCORES_FILE = '/home/node/.n8n/model-scores.json';\n  const TMP_FILE = SCORES_FILE + '.tmp';\n  fs.writeFileSync(TMP_FILE, JSON.stringify(scoresObj, null, 2));\n  fs.renameSync(TMP_FILE, SCORES_FILE);\n\n  await client.end();\n\n  return [{ json: {\n    status: 'collected',\n    models_tracked: rows.length,\n    logs_processed: logsProcessed,\n    storage: 'postgresql+json',\n    timestamp: now\n  }}];\n} catch (err) {\n  try { await client.end(); } catch(e) {}\n  throw err;\n}"
      },
      "id": "d4e5f6a7-4001-4000-8004-000000000003",
      "name": "Aggregate and Score",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [700, 100]
    },
    {
      "parameters": {
        "path": "ai-model-feedback",
        "httpMethod": "POST",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "d4e5f6a7-4001-4000-8004-000000000010",
      "name": "Feedback Webhook",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [260, 400],
      "webhookId": "a81df42c-9bee-4a95-d78a-3b35e7f8a912"
    },
    {
      "parameters": {
        "jsCode": "// Validate webhook secret — supports header (standard) and body.secret (fallback)\nconst data = $input.first().json;\nconst expectedSecret = $env.N8N_WEBHOOK_HMAC_SECRET;\n\nif (!expectedSecret) {\n  throw new Error('N8N_WEBHOOK_HMAC_SECRET env var is not configured');\n}\n\nconst headers = data.headers || {};\nconst body = data.body || data || {};\nconst receivedSecret = headers['x-webhook-secret'] || body.secret || '';\n\nif (receivedSecret !== expectedSecret) {\n  throw new Error('Invalid webhook secret (checked header + body)');\n}\n\nreturn [{\n  json: {\n    model: body.model || '',\n    rating: body.rating || '',\n    agent: body.agent || '',\n    emoji: body.emoji || '',\n    context: body.context || '',\n    authenticated: true\n  }\n}];"
      },
      "id": "d4e5f6a7-4001-4000-8004-000000000011",
      "name": "Validate Feedback Secret",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [480, 400]
    },
    {
      "parameters": {
        "jsCode": "// Record feedback (like/dislike) — PostgreSQL as source of truth + JSON cache\nconst { Client } = require('pg');\nconst fs = require('fs');\n\nconst input = $input.first().json;\nconst model = input.model;\nconst rating = input.rating;\n\nif (!model || !rating) {\n  return [{ json: { status: 'error', message: 'model and rating are required' } }];\n}\n\nconst client = new Client({\n  host: 'postgresql',\n  port: 5432,\n  database: 'n8n',\n  user: 'n8n',\n  password: $env.DB_POSTGRESDB_PASSWORD\n});\n\ntry {\n  await client.connect();\n\n  // UPSERT: create model if not exists, then increment like/dislike\n  const likeInc = rating === 'like' ? 1 : 0;\n  const dislikeInc = rating === 'dislike' ? 1 : 0;\n\n  await client.query(`\n    INSERT INTO model_scores (model, likes, dislikes, source, first_seen, last_updated)\n    VALUES ($1, $2, $3, 'feedback', NOW(), NOW())\n    ON CONFLICT (model) DO UPDATE SET\n      likes = model_scores.likes + $2,\n      dislikes = model_scores.dislikes + $3,\n      last_updated = NOW()\n  `, [model, likeInc, dislikeInc]);\n\n  // Recalculate score for all models (needed for relative metrics)\n  const allModels = await client.query('SELECT * FROM model_scores');\n  const rows = allModels.rows;\n  const maxCost = Math.max(...rows.map(r => r.total_calls > 0 ? r.total_cost / r.total_calls : 0), 0.001);\n  const maxLatency = Math.max(...rows.map(r => r.total_calls > 0 ? r.total_latency_ms / r.total_calls : 0), 1);\n\n  for (const r of rows) {\n    const likeRatio = (r.likes + r.dislikes) > 0 ? r.likes / (r.likes + r.dislikes) : 0.5;\n    const successRate = r.total_calls > 0 ? r.successful_calls / r.total_calls : 1;\n    const avgCost = r.total_calls > 0 ? r.total_cost / r.total_calls : 0;\n    const costEff = 1 - (avgCost / maxCost);\n    const avgLatency = r.total_calls > 0 ? r.total_latency_ms / r.total_calls : 0;\n    const speedScore = 1 - (avgLatency / maxLatency);\n    const score = Math.round((likeRatio * 40) + (successRate * 30) + (costEff * 20) + (speedScore * 10));\n\n    await client.query(\n      'UPDATE model_scores SET score = $1, avg_cost_per_call = $2, avg_latency_ms = $3 WHERE model = $4',\n      [score, Math.round(avgCost * 10000) / 10000, Math.round(avgLatency), r.model]\n    );\n  }\n\n  // Get updated model data for response\n  const result = await client.query('SELECT * FROM model_scores WHERE model = $1', [model]);\n  const updated = result.rows[0] || {};\n\n  // Export JSON cache (atomic write)\n  const allUpdated = await client.query('SELECT * FROM model_scores ORDER BY score DESC');\n  const scoresObj = {};\n  for (const r of allUpdated.rows) {\n    scoresObj[r.model] = {\n      total_calls: r.total_calls, successful_calls: r.successful_calls,\n      failed_calls: r.failed_calls, total_tokens: Number(r.total_tokens),\n      total_cost: r.total_cost, total_latency_ms: r.total_latency_ms,\n      likes: r.likes, dislikes: r.dislikes, score: r.score,\n      avg_cost_per_call: r.avg_cost_per_call, avg_latency_ms: r.avg_latency_ms,\n      source: r.source, first_seen: r.first_seen, last_updated: r.last_updated\n    };\n  }\n  const SCORES_FILE = '/home/node/.n8n/model-scores.json';\n  const TMP_FILE = SCORES_FILE + '.tmp';\n  fs.writeFileSync(TMP_FILE, JSON.stringify(scoresObj, null, 2));\n  fs.renameSync(TMP_FILE, SCORES_FILE);\n\n  await client.end();\n\n  return [{ json: {\n    status: 'recorded', model, rating,\n    new_likes: updated.likes || 0,\n    new_dislikes: updated.dislikes || 0,\n    new_score: updated.score || 50,\n    storage: 'postgresql+json'\n  }}];\n} catch (err) {\n  try { await client.end(); } catch(e) {}\n  throw err;\n}"
      },
      "id": "d4e5f6a7-4001-4000-8004-000000000012",
      "name": "Record Feedback",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [700, 400]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ $json }}",
        "options": {
          "responseCode": 200
        }
      },
      "id": "d4e5f6a7-4001-4000-8004-000000000013",
      "name": "Respond Feedback",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [920, 400]
    },
    {
      "parameters": {
        "path": "ai-model-scores",
        "httpMethod": "POST",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "d4e5f6a7-4001-4000-8004-000000000020",
      "name": "Scores Webhook",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [260, 700],
      "webhookId": "b92ef53d-0aff-5ba6-e89b-4c46f8g9b023"
    },
    {
      "parameters": {
        "jsCode": "// Validate webhook secret — supports header (standard) and body.secret (fallback)\nconst data = $input.first().json;\nconst expectedSecret = $env.N8N_WEBHOOK_HMAC_SECRET;\n\nif (!expectedSecret) {\n  throw new Error('N8N_WEBHOOK_HMAC_SECRET env var is not configured');\n}\n\nconst headers = data.headers || {};\nconst body = data.body || data || {};\nconst receivedSecret = headers['x-webhook-secret'] || body.secret || '';\n\nif (receivedSecret !== expectedSecret) {\n  throw new Error('Invalid webhook secret (checked header + body)');\n}\n\nreturn [{ json: { authenticated: true } }];"
      },
      "id": "d4e5f6a7-4001-4000-8004-000000000021",
      "name": "Validate Scores Secret",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [480, 700]
    },
    {
      "parameters": {
        "jsCode": "// Read model scores from PostgreSQL (source of truth)\nconst { Client } = require('pg');\n\nconst client = new Client({\n  host: 'postgresql',\n  port: 5432,\n  database: 'n8n',\n  user: 'n8n',\n  password: $env.DB_POSTGRESDB_PASSWORD\n});\n\ntry {\n  await client.connect();\n\n  const result = await client.query('SELECT * FROM model_scores ORDER BY score DESC');\n  const sorted = result.rows.map(r => ({\n    model: r.model,\n    score: r.score || 0,\n    likes: r.likes || 0,\n    dislikes: r.dislikes || 0,\n    total_calls: r.total_calls || 0,\n    success_rate: r.total_calls > 0\n      ? Math.round((r.successful_calls / r.total_calls) * 100) + '%'\n      : 'N/A',\n    avg_cost: r.avg_cost_per_call || 0,\n    avg_latency_ms: r.avg_latency_ms || 0,\n    total_cost: Math.round((r.total_cost || 0) * 10000) / 10000,\n    source: r.source || 'unknown',\n    last_updated: r.last_updated || 'never'\n  }));\n\n  await client.end();\n\n  return [{ json: {\n    status: 'success',\n    models_tracked: sorted.length,\n    scores: sorted,\n    storage: 'postgresql',\n    generated_at: new Date().toISOString()\n  }}];\n} catch (err) {\n  try { await client.end(); } catch(e) {}\n  throw err;\n}"
      },
      "id": "d4e5f6a7-4001-4000-8004-000000000022",
      "name": "Read Scores",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [700, 700]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ $json }}",
        "options": {
          "responseCode": 200
        }
      },
      "id": "d4e5f6a7-4001-4000-8004-000000000023",
      "name": "Respond Scores",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [920, 700]
    },
    {
      "parameters": {
        "rule": {
          "interval": [
            {
              "field": "cronExpression",
              "expression": "0 3 * * 1"
            }
          ]
        }
      },
      "id": "d4e5f6a7-4001-4000-8004-000000000030",
      "name": "Cron Weekly Mon 3h",
      "type": "n8n-nodes-base.scheduleTrigger",
      "typeVersion": 1.2,
      "position": [260, 1000]
    },
    {
      "parameters": {
        "method": "GET",
        "url": "https://openrouter.ai/api/v1/models",
        "authentication": "none",
        "options": {
          "response": {
            "response": {
              "fullResponse": true
            }
          },
          "timeout": 30000
        }
      },
      "id": "d4e5f6a7-4001-4000-8004-000000000031",
      "name": "Fetch OpenRouter Models",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [480, 1000]
    },
    {
      "parameters": {
        "jsCode": "// Discover new models from OpenRouter catalog\nconst fs = require('fs');\nconst { Client } = require('pg');\nconst response = $input.first().json;\nconst models = response.body?.data || response.data || [];\nconst SCORES_FILE = '/home/node/.n8n/model-scores.json';\nconst DISCOVERY_FILE = '/home/node/.n8n/model-discovery.json';\nconst TMP_FILE = DISCOVERY_FILE + '.tmp';\n\n// Load existing scores from PostgreSQL to know which models we track\nconst client = new Client({\n  host: 'postgresql', port: 5432, database: 'n8n',\n  user: 'n8n', password: $env.DB_POSTGRESDB_PASSWORD\n});\n\ntry {\n  await client.connect();\n  const existing = await client.query('SELECT model FROM model_scores');\n  const trackedModels = new Set(existing.rows.map(r => r.model));\n  await client.end();\n\n  // Load previous discovery to track history\n  let prevDiscovery = {};\n  try {\n    if (fs.existsSync(DISCOVERY_FILE)) {\n      prevDiscovery = JSON.parse(fs.readFileSync(DISCOVERY_FILE, 'utf8'));\n    }\n  } catch (e) {\n    prevDiscovery = {};\n  }\n\n  const now = new Date().toISOString();\n  const oneWeekAgo = Date.now() - 7 * 24 * 60 * 60 * 1000;\n  const newModels = [];\n  const catalog = {};\n\n  for (const m of models) {\n    if (!m.id || !m.pricing) continue;\n    if (m.architecture?.modality !== 'text->text' && !m.id.includes('/')) continue;\n\n    const inputCost = parseFloat(m.pricing.prompt || '0') * 1000000;\n    const outputCost = parseFloat(m.pricing.completion || '0') * 1000000;\n    const ctx = m.context_length || 0;\n    const created = m.created ? m.created * 1000 : 0;\n\n    catalog[m.id] = {\n      name: m.name || m.id,\n      input_cost_per_m: Math.round(inputCost * 100) / 100,\n      output_cost_per_m: Math.round(outputCost * 100) / 100,\n      context_window: ctx,\n      created_at: created ? new Date(created).toISOString() : 'unknown',\n      top_provider: m.top_provider?.max_completion_tokens || 0\n    };\n\n    const isNew = !trackedModels.has(m.id) && !prevDiscovery[m.id];\n    const isRecent = created > oneWeekAgo;\n    const isCheap = inputCost <= 5;\n    const isBigCtx = ctx >= 32000;\n\n    if ((isNew || isRecent) && isCheap && isBigCtx) {\n      newModels.push({\n        id: m.id, name: m.name || m.id,\n        input_cost: Math.round(inputCost * 100) / 100,\n        output_cost: Math.round(outputCost * 100) / 100,\n        context: ctx, is_free: inputCost === 0 && outputCost === 0,\n        created: created ? new Date(created).toISOString() : 'unknown'\n      });\n    }\n  }\n\n  // Save discovery catalog (atomic write)\n  const discovery = { last_scan: now, total_models: Object.keys(catalog).length, catalog };\n  fs.writeFileSync(TMP_FILE, JSON.stringify(discovery, null, 2));\n  fs.renameSync(TMP_FILE, DISCOVERY_FILE);\n\n  newModels.sort((a, b) => {\n    if (a.is_free !== b.is_free) return a.is_free ? -1 : 1;\n    return a.input_cost - b.input_cost;\n  });\n\n  return [{ json: {\n    status: 'discovered',\n    total_catalog: Object.keys(catalog).length,\n    new_models_found: newModels.length,\n    new_models: newModels.slice(0, 20),\n    scan_date: now\n  }}];\n} catch (err) {\n  try { await client.end(); } catch(e) {}\n  throw err;\n}"
      },
      "id": "d4e5f6a7-4001-4000-8004-000000000032",
      "name": "Analyze New Models",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [700, 1000]
    }
  ],
  "connections": {
    "Cron 6h": {
      "main": [
        [
          {
            "node": "Fetch Spend Logs",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch Spend Logs": {
      "main": [
        [
          {
            "node": "Aggregate and Score",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Feedback Webhook": {
      "main": [
        [
          {
            "node": "Validate Feedback Secret",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Validate Feedback Secret": {
      "main": [
        [
          {
            "node": "Record Feedback",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Record Feedback": {
      "main": [
        [
          {
            "node": "Respond Feedback",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Scores Webhook": {
      "main": [
        [
          {
            "node": "Validate Scores Secret",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Validate Scores Secret": {
      "main": [
        [
          {
            "node": "Read Scores",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Read Scores": {
      "main": [
        [
          {
            "node": "Respond Scores",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Cron Weekly Mon 3h": {
      "main": [
        [
          {
            "node": "Fetch OpenRouter Models",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch OpenRouter Models": {
      "main": [
        [
          {
            "node": "Analyze New Models",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "active": false
}
